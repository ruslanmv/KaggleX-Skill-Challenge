{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Preview:\n",
      "   id    brand          model  model_year  milage fuel_type  \\\n",
      "0   0     Ford   F-150 Lariat        2018   74349  Gasoline   \n",
      "1   1      BMW          335 i        2007   80000  Gasoline   \n",
      "2   2   Jaguar      XF Luxury        2009   91491  Gasoline   \n",
      "3   3      BMW   X7 xDrive40i        2022    2437    Hybrid   \n",
      "4   4  Pontiac  Firebird Base        2001  111000  Gasoline   \n",
      "\n",
      "                                              engine  \\\n",
      "0      375.0HP 3.5L V6 Cylinder Engine Gasoline Fuel   \n",
      "1  300.0HP 3.0L Straight 6 Cylinder Engine Gasoli...   \n",
      "2       300.0HP 4.2L 8 Cylinder Engine Gasoline Fuel   \n",
      "3  335.0HP 3.0L Straight 6 Cylinder Engine Gasoli...   \n",
      "4      200.0HP 3.8L V6 Cylinder Engine Gasoline Fuel   \n",
      "\n",
      "                     transmission ext_col int_col       accident clean_title  \\\n",
      "0                    10-Speed A/T    Blue    Gray  None reported         Yes   \n",
      "1                     6-Speed M/T   Black   Black  None reported         Yes   \n",
      "2                     6-Speed A/T  Purple   Beige  None reported         Yes   \n",
      "3  Transmission w/Dual Shift Mode    Gray   Brown  None reported         Yes   \n",
      "4                             A/T   White   Black  None reported         Yes   \n",
      "\n",
      "   price  \n",
      "0  11000  \n",
      "1   8250  \n",
      "2  15000  \n",
      "3  63500  \n",
      "4   7850  \n",
      "Info.txt file generated successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "# Load the train data\n",
    "cwd = os.getcwd()\n",
    "train_data = pd.read_csv(os.path.join(cwd, 'data', 'train.csv'))\n",
    "# Print the first few rows of the data\n",
    "print(\"Data Preview:\")\n",
    "print(train_data.head())\n",
    "# Get the data description\n",
    "data_description = f\"Data Description:\\n\"\n",
    "data_description += f\"Number of rows: {train_data.shape[0]}\\n\"\n",
    "data_description += f\"Number of columns: {train_data.shape[1]}\\n\"\n",
    "\n",
    "# Get data types for each column\n",
    "data_types = \"Data Types:\\n\"\n",
    "data_types += str(train_data.dtypes) + \"\\n\"\n",
    "# Check for missing values\n",
    "missing_values = \"Missing Values:\\n\"\n",
    "missing_values += str(train_data.isnull().sum()) + \"\\n\"\n",
    "\n",
    "# Check for unique values in each column\n",
    "unique_values = \"Unique Values in Each Column:\\n\"\n",
    "for col in train_data.columns:\n",
    "    unique_values += f\"Column: {col}, Unique Values: {train_data[col].nunique()}\\n\"\n",
    "\n",
    "# Check for categorical columns\n",
    "categorical_cols = [col for col in train_data.columns if train_data[col].dtype == 'object']\n",
    "categorical_cols_str = \"Categorical Columns:\\n\"\n",
    "categorical_cols_str += str(categorical_cols) + \"\\n\"\n",
    "\n",
    "# Check for numerical columns\n",
    "numerical_cols = [col for col in train_data.columns if train_data[col].dtype != 'object']\n",
    "numerical_cols_str = \"Numerical Columns:\\n\"\n",
    "numerical_cols_str += str(numerical_cols) + \"\\n\"\n",
    "\n",
    "# Check for imbalanced classes (if target variable is categorical)\n",
    "target_col = 'target'  # assume the target variable is named 'target'\n",
    "if target_col in train_data.columns and train_data[target_col].dtype == 'object':\n",
    "    class_distribution = \"Class Distribution:\\n\"\n",
    "    class_distribution += str(train_data[target_col].value_counts()) + \"\\n\"\n",
    "\n",
    "# Generate the info.txt file\n",
    "with open('info.txt', 'w') as f:\n",
    "    f.write(\"Machine Learning Problem Information:\\n\\n\")\n",
    "    f.write(\"This file contains information about the machine learning problem, including data description, data types, missing values, unique values, categorical and numerical columns, and class distribution (if applicable).\\n\\n\")\n",
    "    f.write(data_description)\n",
    "    f.write(data_types)\n",
    "    f.write(missing_values)\n",
    "    f.write(unique_values)\n",
    "    f.write(categorical_cols_str)\n",
    "    f.write(numerical_cols_str)\n",
    "    if target_col in train_data.columns and train_data[target_col].dtype == 'object':\n",
    "        f.write(class_distribution)\n",
    "\n",
    "print(\"Info.txt file generated successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Preview:\n",
      "   id    brand          model  model_year  milage fuel_type  \\\n",
      "0   0     Ford   F-150 Lariat        2018   74349  Gasoline   \n",
      "1   1      BMW          335 i        2007   80000  Gasoline   \n",
      "2   2   Jaguar      XF Luxury        2009   91491  Gasoline   \n",
      "3   3      BMW   X7 xDrive40i        2022    2437    Hybrid   \n",
      "4   4  Pontiac  Firebird Base        2001  111000  Gasoline   \n",
      "\n",
      "                                              engine  \\\n",
      "0      375.0HP 3.5L V6 Cylinder Engine Gasoline Fuel   \n",
      "1  300.0HP 3.0L Straight 6 Cylinder Engine Gasoli...   \n",
      "2       300.0HP 4.2L 8 Cylinder Engine Gasoline Fuel   \n",
      "3  335.0HP 3.0L Straight 6 Cylinder Engine Gasoli...   \n",
      "4      200.0HP 3.8L V6 Cylinder Engine Gasoline Fuel   \n",
      "\n",
      "                     transmission ext_col int_col       accident clean_title  \\\n",
      "0                    10-Speed A/T    Blue    Gray  None reported         Yes   \n",
      "1                     6-Speed M/T   Black   Black  None reported         Yes   \n",
      "2                     6-Speed A/T  Purple   Beige  None reported         Yes   \n",
      "3  Transmission w/Dual Shift Mode    Gray   Brown  None reported         Yes   \n",
      "4                             A/T   White   Black  None reported         Yes   \n",
      "\n",
      "   price  \n",
      "0  11000  \n",
      "1   8250  \n",
      "2  15000  \n",
      "3  63500  \n",
      "4   7850  \n",
      "Info.json file generated successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Load the train data\n",
    "cwd = os.getcwd()\n",
    "train_data = pd.read_csv(os.path.join(cwd, 'data', 'train.csv'))\n",
    "# Print the first few rows of the data\n",
    "print(\"Data Preview:\")\n",
    "print(train_data.head())\n",
    "# Get the data description\n",
    "data_description = {\n",
    "    \"Machine Learning Problem Information\": \"This file contains information about the machine learning problem, including data description, data types, missing values, unique values, categorical and numerical columns, and class distribution (if applicable).\",\n",
    "    \"Data Description\": {\n",
    "        \"number_of_rows\": train_data.shape[0],\n",
    "        \"number_of_columns\": train_data.shape[1]\n",
    "    }\n",
    "}\n",
    "# Get data types for each column\n",
    "data_types = {\n",
    "    \"Data Types\": \"This section describes the data types for each column.\",\n",
    "    \"types\": {col: str(dtype) for col, dtype in zip(train_data.columns, train_data.dtypes)}\n",
    "}\n",
    "\n",
    "missing_values = \"Missing Values:\\n\"\n",
    "missing_values += str(train_data.isnull().sum()) + \"\\n\"\n",
    "\n",
    "# Check for missing values\n",
    "missing_values = {\n",
    "    \"Missing Values\": \"This section describes the number of missing values in each column.\",\n",
    "    \"counts\": {col: sum(train_data[col].isnull()) for col in train_data.columns}\n",
    "}\n",
    "# Check for unique values in each column\n",
    "unique_values = {\n",
    "    \"Unique Values in Each Column\": \"This section describes the number of unique values in each column.\",\n",
    "    \"counts\": {col: train_data[col].nunique() for col in train_data.columns}\n",
    "}\n",
    "# Check for categorical columns\n",
    "categorical_cols = [col for col in train_data.columns if train_data[col].dtype == 'object']\n",
    "categorical_cols_info = {\n",
    "    \"Categorical Columns\": \"This section lists the categorical columns in the dataset.\",\n",
    "    \"columns\": categorical_cols\n",
    "}\n",
    "# Check for numerical columns\n",
    "numerical_cols = [col for col in train_data.columns if train_data[col].dtype != 'object']\n",
    "numerical_cols_info = {\n",
    "    \"Numerical Columns\": \"This section lists the numerical columns in the dataset.\",\n",
    "    \"columns\": numerical_cols\n",
    "}\n",
    "# Check for imbalanced classes (if target variable is categorical)\n",
    "target_col = 'price'  # assume the target variable is named 'target'\n",
    "if target_col in train_data.columns and train_data[target_col].dtype == 'object':\n",
    "    class_distribution = {\n",
    "        \"Class Distribution\": \"This section describes the class distribution of the target variable.\",\n",
    "        \"distribution\": {cls: count for cls, count in train_data[target_col].value_counts().items()}\n",
    "    }\n",
    "# Generate the info.json file\n",
    "info_dict = {\n",
    "    **data_description,\n",
    "    **data_types,\n",
    "    **missing_values,\n",
    "    \"Unique Values in Each Column\": unique_values,\n",
    "    \"Categorical Columns\": categorical_cols_info,\n",
    "    \"Numerical Columns\": numerical_cols_info\n",
    "}\n",
    "\n",
    "if target_col in train_data.columns and train_data[target_col].dtype == 'object':\n",
    "    info_dict[\"Class Distribution\"] = class_distribution\n",
    "with open('info.json', 'w') as f:\n",
    "    json.dump(info_dict, f, indent=4)\n",
    "\n",
    "print(\"Info.json file generated successfully!\")    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "\n",
    "def get_evaluation_metric(info_json, target_variable):\n",
    "    # Load the info.json file\n",
    "    with open(info_json, 'r') as f:\n",
    "        info = json.load(f)\n",
    "\n",
    "    # Get the data types of the columns\n",
    "    data_types = info['types']\n",
    "\n",
    "    # Check if the target variable is numerical or categorical\n",
    "    if data_types[target_variable] == 'int64' or data_types[target_variable] == 'float64':\n",
    "        # Numerical target variable, suggest evaluation metrics\n",
    "        evaluation_metrics = ['Mean Squared Error (MSE)', 'Mean Absolute Error (MAE)', 'R-Squared', 'Root Mean Squared Error (RMSE)']\n",
    "    else:\n",
    "        # Categorical target variable, suggest evaluation metrics\n",
    "        evaluation_metrics = ['Accuracy', 'F1-Score', 'Precision', 'Recall']\n",
    "\n",
    "    # Create a dictionary to store the results\n",
    "    results = {\n",
    "        'Evaluation Metrics': evaluation_metrics,\n",
    "        'Target Variable': target_variable,\n",
    "        'Data Type': data_types[target_variable]\n",
    "    }\n",
    "\n",
    "    # Save the results to a new JSON file\n",
    "    with open('evaluation_metrics.json', 'w') as f:\n",
    "        json.dump(results, f, indent=4)\n",
    "\n",
    "    print(\"Results saved to evaluation_metrics.json\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to evaluation_metrics.json\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "get_evaluation_metric('info.json', 'price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full JSON prompt:\n",
      "{\n",
      "    \"problem_type\": \"regression\",\n",
      "    \"specific_metric_importance\": \"Mean Squared Error (MSE) is the most important metric\",\n",
      "    \"important_features\": [\n",
      "        \"id\",\n",
      "        \"model_year\",\n",
      "        \"milage\",\n",
      "        \"price\"\n",
      "    ],\n",
      "    \"missing_value_strategy\": \"no missing values, no strategy needed\",\n",
      "    \"data_distribution_assumptions\": \"non-normality assumed due to categorical features\",\n",
      "    \"desired_outcome\": \"predict the continuous target variable with high accuracy\",\n",
      "    \"target_variable\": \"price\",\n",
      "    \"target_data_type\": \"int64\",\n",
      "    \"evaluation_metrics\": {\n",
      "        \"Evaluation Metrics\": [\n",
      "            \"Mean Squared Error (MSE)\",\n",
      "            \"Mean Absolute Error (MAE)\",\n",
      "            \"R-Squared\",\n",
      "            \"Root Mean Squared Error (RMSE)\"\n",
      "        ],\n",
      "        \"Target Variable\": \"price\",\n",
      "        \"Data Type\": \"int64\"\n",
      "    },\n",
      "    \"num_rows\": 54273,\n",
      "    \"num_cols\": 13,\n",
      "    \"data_types\": {\n",
      "        \"id\": \"int64\",\n",
      "        \"brand\": \"object\",\n",
      "        \"model\": \"object\",\n",
      "        \"model_year\": \"int64\",\n",
      "        \"milage\": \"int64\",\n",
      "        \"fuel_type\": \"object\",\n",
      "        \"engine\": \"object\",\n",
      "        \"transmission\": \"object\",\n",
      "        \"ext_col\": \"object\",\n",
      "        \"int_col\": \"object\",\n",
      "        \"accident\": \"object\",\n",
      "        \"clean_title\": \"object\",\n",
      "        \"price\": \"int64\"\n",
      "    },\n",
      "    \"missing_values\": {\n",
      "        \"id\": 0,\n",
      "        \"brand\": 0,\n",
      "        \"model\": 0,\n",
      "        \"model_year\": 0,\n",
      "        \"milage\": 0,\n",
      "        \"fuel_type\": 0,\n",
      "        \"engine\": 0,\n",
      "        \"transmission\": 0,\n",
      "        \"ext_col\": 0,\n",
      "        \"int_col\": 0,\n",
      "        \"accident\": 0,\n",
      "        \"clean_title\": 0,\n",
      "        \"price\": 0\n",
      "    },\n",
      "    \"unique_values\": {\n",
      "        \"Unique Values in Each Column\": \"This section describes the number of unique values in each column.\",\n",
      "        \"counts\": {\n",
      "            \"id\": 54273,\n",
      "            \"brand\": 53,\n",
      "            \"model\": 1827,\n",
      "            \"model_year\": 34,\n",
      "            \"milage\": 3212,\n",
      "            \"fuel_type\": 7,\n",
      "            \"engine\": 1061,\n",
      "            \"transmission\": 46,\n",
      "            \"ext_col\": 260,\n",
      "            \"int_col\": 124,\n",
      "            \"accident\": 2,\n",
      "            \"clean_title\": 1,\n",
      "            \"price\": 1481\n",
      "        }\n",
      "    },\n",
      "    \"categorical_cols\": [\n",
      "        \"brand\",\n",
      "        \"model\",\n",
      "        \"fuel_type\",\n",
      "        \"engine\",\n",
      "        \"transmission\",\n",
      "        \"ext_col\",\n",
      "        \"int_col\",\n",
      "        \"accident\",\n",
      "        \"clean_title\"\n",
      "    ],\n",
      "    \"numerical_cols\": [\n",
      "        \"id\",\n",
      "        \"model_year\",\n",
      "        \"milage\",\n",
      "        \"price\"\n",
      "    ],\n",
      "    \"info\": {\n",
      "        \"Data Description\": {\n",
      "            \"number_of_rows\": 54273,\n",
      "            \"number_of_columns\": 13\n",
      "        },\n",
      "        \"Data Types\": \"This section describes the data types for each column.\",\n",
      "        \"Missing Values\": \"This section describes the number of missing values in each column.\",\n",
      "        \"Unique Values in Each Column\": {\n",
      "            \"Unique Values in Each Column\": \"This section describes the number of unique values in each column.\",\n",
      "            \"counts\": {\n",
      "                \"id\": 54273,\n",
      "                \"brand\": 53,\n",
      "                \"model\": 1827,\n",
      "                \"model_year\": 34,\n",
      "                \"milage\": 3212,\n",
      "                \"fuel_type\": 7,\n",
      "                \"engine\": 1061,\n",
      "                \"transmission\": 46,\n",
      "                \"ext_col\": 260,\n",
      "                \"int_col\": 124,\n",
      "                \"accident\": 2,\n",
      "                \"clean_title\": 1,\n",
      "                \"price\": 1481\n",
      "            }\n",
      "        },\n",
      "        \"Categorical Columns\": {\n",
      "            \"Categorical Columns\": \"This section lists the categorical columns in the dataset.\",\n",
      "            \"columns\": [\n",
      "                \"brand\",\n",
      "                \"model\",\n",
      "                \"fuel_type\",\n",
      "                \"engine\",\n",
      "                \"transmission\",\n",
      "                \"ext_col\",\n",
      "                \"int_col\",\n",
      "                \"accident\",\n",
      "                \"clean_title\"\n",
      "            ]\n",
      "        },\n",
      "        \"Numerical Columns\": {\n",
      "            \"Numerical Columns\": \"This section lists the numerical columns in the dataset.\",\n",
      "            \"columns\": [\n",
      "                \"id\",\n",
      "                \"model_year\",\n",
      "                \"milage\",\n",
      "                \"price\"\n",
      "            ]\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "# Load info.json file\n",
    "with open('info.json') as f:\n",
    "    info_data = json.load(f)\n",
    "# Load evaluation_metrics.json file\n",
    "with open('evaluation_metrics.json') as f:\n",
    "    eval_metrics_data = json.load(f)\n",
    "# Extract essential information from info.json\n",
    "num_rows = info_data['Data Description']['number_of_rows']\n",
    "num_cols = info_data['Data Description']['number_of_columns']\n",
    "data_types = info_data['types']\n",
    "missing_values = info_data['counts']\n",
    "unique_values = info_data['Unique Values in Each Column']\n",
    "categorical_cols = info_data['Categorical Columns']['columns']\n",
    "numerical_cols = info_data['Numerical Columns']['columns']\n",
    "# Extract essential information from evaluation_metrics.json\n",
    "target_variable = eval_metrics_data['Target Variable']\n",
    "target_data_type = eval_metrics_data['Data Type']\n",
    "evaluation_metrics = eval_metrics_data['Evaluation Metrics']\n",
    "# Infer problem type based on target variable data type\n",
    "if target_data_type == 'int64' or target_data_type == 'float64':\n",
    "    problem_type = 'regression'\n",
    "else:\n",
    "    problem_type = 'classification'\n",
    "# Ask for optional problem type input\n",
    "optional_problem_type = input(\"Is this a regression problem or a classification problem? (optional, default is inferred) \")\n",
    "if optional_problem_type:\n",
    "    problem_type = optional_problem_type\n",
    "# Decide on specific metric importance based on evaluation metrics\n",
    "specific_metric_importance = 'all metrics are equally importance'\n",
    "if 'Mean Squared Error (MSE)' in evaluation_metrics:\n",
    "    specific_metric_importance = 'Mean Squared Error (MSE) is the most important metric'\n",
    "elif 'Mean Absolute Error (MAE)' in evaluation_metrics:\n",
    "    specific_metric_importance = 'Mean Absolute Error (MAE) is the most important metric'\n",
    "\n",
    "# Decide on important features based on data types and missing values\n",
    "important_features = [col for col in data_types if data_types[col] != 'object' and missing_values[col] == 0]\n",
    "# Decide on missing value strategy based on missing values counts\n",
    "if max(missing_values.values()) > 0:\n",
    "    missing_value_strategy = 'imputation with mean/median'\n",
    "else:\n",
    "    missing_value_strategy = 'no missing values, no strategy needed'\n",
    "# Decide on data distribution assumptions based on data types\n",
    "data_distribution_assumptions = 'normality assumed'\n",
    "if any(col in categorical_cols for col in data_types):\n",
    "    data_distribution_assumptions = 'non-normality assumed due to categorical features'\n",
    "# Decide on desired outcome based on target variable and problem type\n",
    "desired_outcome = 'predict the target  variable with high accuracy'\n",
    "if problem_type == 'regression':\n",
    "    desired_outcome = 'predict the continuous target variable with high accuracy'\n",
    "else:\n",
    "    desired_outcome = 'predict the categorical target variable with high accuracy'\n",
    "# Create full JSON prompt with added comments\n",
    "prompt = {\n",
    "    # Problem type inferred based on target variable data type\n",
    "    \"problem_type\": problem_type,\n",
    "    # Metrie decided based on evaluation metrics\n",
    "    \"specific_metric_importance\": specific_metric_importance,\n",
    "    # Important features decided based on data types and missing values\n",
    "    \"important_features\": important_features,\n",
    "    # Missing value strategy decided based on missing values counts\n",
    "    \"missing_value_strategy\": missing_value_strategy,\n",
    "    # Data distribution assumptions decided based on data types\n",
    "    \"data_distribution_assumptions\": data_distribution_assumptions,\n",
    "    # Desired outcome decided based on target variable and problem type\n",
    "    \"desired_outcome\": desired_outcome,\n",
    "    # Information from evaluation_metrics.json\n",
    "    \"target_variable\": target_variable,\n",
    "    \"target_data_type\": target_data_type,\n",
    "    \"evaluation_metrics\": evaluation_metrics,\n",
    "    # Information from info.json\n",
    "    \"num_rows\": num_rows,\n",
    "    \"num_cols\": num_cols,\n",
    "    \"data_types\": data_types,\n",
    "    \"missing_values\": missing_values,\n",
    "    \"unique_values\": unique_values,\n",
    "    \"categorical_cols\": categorical_cols,\n",
    "    \"numerical_cols\": numerical_cols,\n",
    "    \"info\": {\n",
    "        # Data description section\n",
    "        \"Data Description\": info_data[\"Data Description\"],\n",
    "        # Data types section\n",
    "        \"Data Types\": info_data[\"Data Types\"],\n",
    "        # Missing values section\n",
    "        \"Missing Values\": info_data[\"Missing Values\"],\n",
    "        # Unique values section\n",
    "        \"Unique Values in Each Column\": info_data[\"Unique Values in Each Column\"],\n",
    "        # Categorical columns section\n",
    "        \"Categorical Columns\": info_data[\"Categorical Columns\"],\n",
    "        # Numerical columns section\n",
    "        \"Numerical Columns\": info_data[\"Numerical Columns\"]\n",
    "    },\n",
    "    # Evaluation metrics section\n",
    "    \"evaluation_metrics\": eval_metrics_data\n",
    "}\n",
    "# Save the JSON prompt to a file\n",
    "with open('output.json', 'w') as f:\n",
    "    json.dump(prompt, f, indent=4)\n",
    "print(\"Full JSON prompt:\")\n",
    "print(json.dumps(prompt, indent=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full prompt:\n",
      "\n",
      "    You are tasked with recommending the most suitable machine learning methods to solve the following problem:\n",
      "\n",
      "    ## Problem Description\n",
      "    We are working on a regression problem to predict the price. The dataset contains various features related to the data. The goal is to build a model that can accurately predict the price based on these features.\n",
      "\n",
      "    ## Dataset Information\n",
      "    - Number of Rows: 54273\n",
      "    - Number of Columns: 13\n",
      "    - Target Variable: price (data type: int64)\n",
      "    - Data Types: {'id': 'int64', 'brand': 'object', 'model': 'object', 'model_year': 'int64', 'milage': 'int64', 'fuel_type': 'object', 'engine': 'object', 'transmission': 'object', 'ext_col': 'object', 'int_col': 'object', 'accident': 'object', 'clean_title': 'object', 'price': 'int64'}\n",
      "    - Missing Values: {'id': 0, 'brand': 0, 'model': 0, 'model_year': 0, 'milage': 0, 'fuel_type': 0, 'engine': 0, 'transmission': 0, 'ext_col': 0, 'int_col': 0, 'accident': 0, 'clean_title': 0, 'price': 0}\n",
      "    - Categorical Columns: ['brand', 'model', 'fuel_type', 'engine', 'transmission', 'ext_col', 'int_col', 'accident', 'clean_title']\n",
      "    - Numerical Columns: ['id', 'model_year', 'milage', 'price']\n",
      "\n",
      "    ## Evaluation Metrics\n",
      "    The performance of the model will be evaluated using the following metrics:\n",
      "    - Mean Squared Error (MSE)\n",
      "- Mean Absolute Error (MAE)\n",
      "- R-Squared\n",
      "- Root Mean Squared Error (RMSE)\n",
      "\n",
      "    ## Specific Requirements and Constraints\n",
      "    - Handle missing values appropriately. \n",
      "    - The target variable is price, which is of type int64.\n",
      "    - Some features are categorical and will need to be encoded properly.\n",
      "    - There might be non-linear relationships between the features and the target variable.\n",
      "\n",
      "    ## Additional Information\n",
      "    - Important features to consider include numerical columns without missing values and categorical columns.\n",
      "    - Assume normality for numerical features but be cautious of non-normality due to categorical features.\n",
      "\n",
      "    ## Task\n",
      "    Recommend the most suitable machine learning methods and preprocessing steps to solve this regression problem, considering the given dataset, requirements, and evaluation metrics. Provide a detailed explanation for your recommendations, including:\n",
      "    1. Data preprocessing steps to handle missing values and encode categorical variables.\n",
      "    2. Feature selection or extraction methods.\n",
      "    3. Suitable regression algorithms.\n",
      "    4. Model evaluation techniques and any potential model improvement strategies.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Load info.json file\n",
    "with open('info.json') as f:\n",
    "    info_data = json.load(f)\n",
    "\n",
    "# Load evaluation_metrics.json file\n",
    "with open('evaluation_metrics.json') as f:\n",
    "    eval_metrics_data = json.load(f)\n",
    "\n",
    "# Function to generate prompt based on provided data and target variable\n",
    "def generate_prompt(target_variable, target_data_type):\n",
    "    # Extract essential information from info.json\n",
    "    num_rows = info_data['Data Description']['number_of_rows']\n",
    "    num_cols = info_data['Data Description']['number_of_columns']\n",
    "    data_types = info_data['types']\n",
    "    missing_values = info_data['counts']\n",
    "    categorical_cols = [col for col, dtype in data_types.items() if dtype == 'object']\n",
    "    numerical_cols = [col for col, dtype in data_types.items() if dtype in ['int64', 'float64']]\n",
    "    \n",
    "    # Extract essential information from evaluation_metrics.json\n",
    "    evaluation_metrics = eval_metrics_data['Evaluation Metrics']\n",
    "\n",
    "    # Infer problem type based on target variable data type\n",
    "    if target_data_type == 'int64' or target_data_type == 'float64':\n",
    "        problem_type = 'regression'\n",
    "    else:\n",
    "        problem_type = 'classification'\n",
    "\n",
    "    # Construct the prompt\n",
    "    prompt = f\"\"\"\n",
    "    You are tasked with recommending the most suitable machine learning methods to solve the following problem:\n",
    "\n",
    "    ## Problem Description\n",
    "    We are working on a {problem_type} problem to predict the {target_variable}. The dataset contains various features related to the data. The goal is to build a model that can accurately predict the {target_variable} based on these features.\n",
    "\n",
    "    ## Dataset Information\n",
    "    - Number of Rows: {num_rows}\n",
    "    - Number of Columns: {num_cols}\n",
    "    - Target Variable: {target_variable} (data type: {target_data_type})\n",
    "    - Data Types: {data_types}\n",
    "    - Missing Values: {missing_values}\n",
    "    - Categorical Columns: {categorical_cols}\n",
    "    - Numerical Columns: {numerical_cols}\n",
    "\n",
    "    ## Evaluation Metrics\n",
    "    The performance of the model will be evaluated using the following metrics:\n",
    "    - {'\\n- '.join(evaluation_metrics)}\n",
    "\n",
    "    ## Specific Requirements and Constraints\n",
    "    - Handle missing values appropriately. \n",
    "    - The target variable is {target_variable}, which is of type {target_data_type}.\n",
    "    - Some features are categorical and will need to be encoded properly.\n",
    "    - There might be non-linear relationships between the features and the target variable.\n",
    "\n",
    "    ## Additional Information\n",
    "    - Important features to consider include numerical columns without missing values and categorical columns.\n",
    "    - Assume normality for numerical features but be cautious of non-normality due to categorical features.\n",
    "\n",
    "    ## Task\n",
    "    Recommend the most suitable machine learning methods and preprocessing steps to solve this {problem_type} problem, considering the given dataset, requirements, and evaluation metrics. Provide a detailed explanation for your recommendations, including:\n",
    "    1. Data preprocessing steps to handle missing values and encode categorical variables.\n",
    "    2. Feature selection or extraction methods.\n",
    "    3. Suitable {problem_type} algorithms.\n",
    "    4. Model evaluation techniques and any potential model improvement strategies.\n",
    "    \"\"\"\n",
    "\n",
    "    return prompt\n",
    "\n",
    "# Example usage with a specific target variable\n",
    "target_variable = 'price'\n",
    "target_data_type = 'int64'\n",
    "prompt = generate_prompt(target_variable, target_data_type)\n",
    "\n",
    "print(\"Full prompt:\")\n",
    "print(prompt)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "kaggle"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
